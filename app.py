import streamlit as st
from langchain.chains import ConversationChain
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_groq import ChatGroq
from dotenv import load_dotenv
import os

def main():
    # Load environment variables from .env file
    load_dotenv()

    # Get Groq API key from environment
    groq_api_key = os.getenv('GROQ_API_KEY')

    # Set up Streamlit interface
    st.title("CoalIndia Chatbot!")
    st.write("Please ask questions related to the coal and mining industry. Use keywords like 'coal' and 'mining' to get the best responses.")

    # Define memory for conversation
    conversational_memory_length = 5
    memory = ConversationBufferWindowMemory(k=conversational_memory_length)

    # Initialize Groq Langchain chat object and conversation
    model = 'mixtral-8x7b-32768'  # Default model
    groq_chat = ChatGroq(groq_api_key=groq_api_key, model_name=model)
    conversation = ConversationChain(llm=groq_chat, memory=memory)

    user_question = st.text_input("Ask a question:")

    # Display input message
    if user_question:
        st.write(f"User: {user_question}")
        
        # Ensure the query is related to the mining industry
        if "mining" in user_question.lower() or "coal" in user_question.lower():
            # The chatbot's answer is generated by sending the full prompt to the Groq API
            response = conversation(user_question)
            st.write(f"Chatbot: {response['response']}")
        else:
            st.warning("Please ask a question related to the mining industry.")

if __name__ == "__main__":
    main()
